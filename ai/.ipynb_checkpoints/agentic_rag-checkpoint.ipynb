{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Agentic RAG: A Minimal Implementation\n",
                "\n",
                "This notebook demonstrates an **Agentic RAG** system. Unlike traditional RAG (which retrieves -> generates), an Agentic RAG can:\n",
                "1.  **Decide** whether to retrieve information or not.\n",
                "2.  **Refine** its search queries based on initial findings.\n",
                "3.  **Synthesize** information from multiple steps.\n",
                "\n",
                "We will use `LangChain` and `LangGraph` for this demonstration."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mFailed to start the Kernel. \n",
                        "\u001b[1;31merror: externally-managed-environment\n",
                        "\u001b[1;31m\n",
                        "\u001b[1;31m× This environment is externally managed\n",
                        "\u001b[1;31m╰─> To install Python packages system-wide, try brew install\n",
                        "\u001b[1;31m    xyz, where xyz is the package you are trying to\n",
                        "\u001b[1;31m    install.\n",
                        "\u001b[1;31m    \n",
                        "\u001b[1;31m    If you wish to install a Python library that isn't in Homebrew,\n",
                        "\u001b[1;31m    use a virtual environment:\n",
                        "\u001b[1;31m    \n",
                        "\u001b[1;31m    python3 -m venv path/to/venv\n",
                        "\u001b[1;31m    source path/to/venv/bin/activate\n",
                        "\u001b[1;31m    python3 -m pip install xyz\n",
                        "\u001b[1;31m    \n",
                        "\u001b[1;31m    If you wish to install a Python application that isn't in Homebrew,\n",
                        "\u001b[1;31m    it may be easiest to use 'pipx install xyz', which will manage a\n",
                        "\u001b[1;31m    virtual environment for you. You can install pipx with\n",
                        "\u001b[1;31m    \n",
                        "\u001b[1;31m    brew install pipx\n",
                        "\u001b[1;31m    \n",
                        "\u001b[1;31m    You may restore the old behavior of pip by passing\n",
                        "\u001b[1;31m    the '--break-system-packages' flag to pip, or by adding\n",
                        "\u001b[1;31m    'break-system-packages = true' to your pip.conf file. The latter\n",
                        "\u001b[1;31m    will permanently disable this error.\n",
                        "\u001b[1;31m    \n",
                        "\u001b[1;31m    If you disable this error, we STRONGLY recommend that you additionally\n",
                        "\u001b[1;31m    pass the '--user' flag to pip, or set 'user = true' in your pip.conf\n",
                        "\u001b[1;31m    file. Failure to do this can result in a broken Homebrew installation.\n",
                        "\u001b[1;31m    \n",
                        "\u001b[1;31m    Read more about this behavior here: <https://peps.python.org/pep-0668/>\n",
                        "\u001b[1;31m\n",
                        "\u001b[1;31mnote: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
                        "\u001b[1;31mhint: See PEP 668 for the detailed specification. \n",
                        "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
                    ]
                }
            ],
            "source": [
                "# Install necessary packages\n",
                "%pip install -q langchain langchain-openai langchain-community chromadb langgraph"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import getpass\n",
                "\n",
                "# Set OpenAI API Key\n",
                "if \"OPENAI_API_KEY\" not in os.environ:\n",
                "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Vector Store (The \"Knowledge Base\")\n",
                "We'll create a simple in-memory vector store with some dummy data about a fictional company \"Nostra\"."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_community.vectorstores import Chroma\n",
                "from langchain_openai import OpenAIEmbeddings\n",
                "from langchain.schema import Document\n",
                "\n",
                "# Dummy documents\n",
                "docs = [\n",
                "    Document(page_content=\"Nostra is a prediction market platform running on Arbitrum.\", metadata={\"source\": \"overview\"}),\n",
                "    Document(page_content=\"Nostra allows users to trade on future events like Sports and Politics.\", metadata={\"source\": \"features\"}),\n",
                "    Document(page_content=\"The native token of Nostra is NST, used for governance and fee rebates.\", metadata={\"source\": \"tokenomics\"}),\n",
                "    Document(page_content=\"Nostra uses a CTF (Conditional Token Framework) for its market resolution.\", metadata={\"source\": \"tech\"}),\n",
                "]\n",
                "\n",
                "# Create Vector Store\n",
                "embeddings = OpenAIEmbeddings()\n",
                "vectorstore = Chroma.from_documents(docs, embeddings, collection_name=\"nostra_docs\")\n",
                "retriever = vectorstore.as_retriever()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Define Tools\n",
                "The agent needs a tool to access the vector store."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.tools.retriever import create_retriever_tool\n",
                "\n",
                "tool = create_retriever_tool(\n",
                "    retriever,\n",
                "    \"search_nostra_docs\",\n",
                "    \"Searches and returns information about the Nostra prediction market platform.\"\n",
                ")\n",
                "tools = [tool]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Build the Agent (Using LangGraph)\n",
                "We will use a pre-built ReAct agent structure from LangGraph."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langgraph.prebuilt import create_react_agent\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "# Initialize LLM\n",
                "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
                "\n",
                "# Create Agent\n",
                "agent_executor = create_react_agent(llm, tools)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run the Agent\n",
                "Let's ask a question that requires retrieval."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query = \"What framework does Nostra use for market resolution?\"\n",
                "\n",
                "print(f\"User: {query}\\n\")\n",
                "for chunk in agent_executor.stream({\"messages\": [(\"human\", query)]}):\n",
                "    print(chunk)\n",
                "    print(\"----\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Advanced: Inspecting the Trace\n",
                "The output above shows the agent's reasoning steps:\n",
                "1.  It identifies it needs to search.\n",
                "2.  It calls `search_nostra_docs`.\n",
                "3.  It receives the context.\n",
                "4.  It synthesizes the final answer."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
