{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d085a3bc",
   "metadata": {},
   "source": [
    "# Agentic RAG: A Minimal Implementation\n",
    "\n",
    "This notebook demonstrates an **Agentic RAG** system. Unlike traditional RAG (which retrieves -> generates), an Agentic RAG can:\n",
    "1.  **Decide** whether to retrieve information or not.\n",
    "2.  **Refine** its search queries based on initial findings.\n",
    "3.  **Synthesize** information from multiple steps.\n",
    "\n",
    "### Reflection vs Reflexion vs Agentic RAG\n",
    "- **Reflection agent**: a general pattern where an agent critiques its own draft answer (often with a second pass of the same model) before responding. Use this when accuracy matters more than latency and you want self-review without extra tools. Great for short-form Q&A, summaries, or emails.\n",
    "- **Reflexion agent** (per the Reflexion paper): extends reflection by storing critiques in long-term memory so future attempts improve. Use it for tasks that need multiple tries with learning across attempts (coding contests, math puzzles, iterative planning).\n",
    "- **Agentic RAG**: blends tool use + retrieval. The agent plans which tool calls to make (e.g., vector search, web search) before composing the answer. Use it when fresh or grounded knowledge is required or when the corpus is too large to preload into context.\n",
    "\n",
    "**Which one to choose?** Agentic RAG is more flexible but also heavier: it needs tool wiring, retrieval latency, and costs more tokens. Prefer it when factual grounding matters. Stick to Reflection when you just need a quick double-check, and reach for Reflexion when the agent must improve across repeated attempts. For many apps, combining techniques (e.g., Reflection + Agentic RAG) gives the best trade-off.\n",
    "\n",
    "We will use `LangChain` and `LangGraph` for this demonstration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ffcd3f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jay/work/task/ai/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "%pip install -q -U langchain langchain-openai langchain-community chromadb langgraph python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1d3c094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env if present and expose helper for mandatory keys\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def ensure_env_var(key: str) -> str:\n",
    "    value = os.environ.get(key)\n",
    "    if value:\n",
    "        return value\n",
    "    raise EnvironmentError(f\"Missing required environment variable: {key}\")\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = ensure_env_var(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950a733d",
   "metadata": {},
   "source": [
    "## 1. Setup Vector Store (The \"Knowledge Base\")\n",
    "We'll create a simple in-memory vector store with some dummy data about a fictional company \"Nostra\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "416502be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Iterable, Mapping, Sequence\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CorpusConfig:\n",
    "    collection_name: str = \"nostra_docs\"\n",
    "    default_metadata: Mapping[str, str] = field(default_factory=dict)\n",
    "\n",
    "\n",
    "def _normalize_docs(raw_docs: Iterable[Mapping[str, str]], default_meta: Mapping[str, str]) -> Sequence[Document]:\n",
    "    docs: list[Document] = []\n",
    "    for item in raw_docs:\n",
    "        content = item.get(\"page_content\") or item.get(\"content\")\n",
    "        if not content:\n",
    "            continue\n",
    "        metadata = {**default_meta, **item.get(\"metadata\", {})}\n",
    "        docs.append(Document(page_content=content, metadata=metadata))\n",
    "    if not docs:\n",
    "        raise ValueError(\"At least one document with page_content is required\")\n",
    "    return docs\n",
    "\n",
    "\n",
    "def build_retriever(raw_docs: Iterable[Mapping[str, str]], config: CorpusConfig | None = None):\n",
    "    config = config or CorpusConfig()\n",
    "    docs = _normalize_docs(raw_docs, config.default_metadata)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = Chroma.from_documents(docs, embeddings, collection_name=config.collection_name)\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "DEFAULT_DOCS = [\n",
    "    {\"page_content\": \"Nostra is a prediction market platform running on Arbitrum.\", \"metadata\": {\"source\": \"overview\"}},\n",
    "    {\"page_content\": \"Nostra allows users to trade on future events like Sports and Politics.\", \"metadata\": {\"source\": \"features\"}},\n",
    "    {\"page_content\": \"The native token of Nostra is NST, used for governance and fee rebates.\", \"metadata\": {\"source\": \"tokenomics\"}},\n",
    "    {\"page_content\": \"Nostra uses a CTF (Conditional Token Framework) for its market resolution.\", \"metadata\": {\"source\": \"tech\"}},\n",
    "]\n",
    "\n",
    "retriever = build_retriever(DEFAULT_DOCS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d13540",
   "metadata": {},
   "source": [
    "## 2. Define Tools\n",
    "The agent needs a tool to access the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "631272d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "\n",
    "def make_search_tool(retriever, *, name: str = \"search_docs\", description: str | None = None):\n",
    "    desc = description or \"Retrieves grounded knowledge snippets for the agent.\"\n",
    "\n",
    "    def _search(query: str):\n",
    "        return retriever.invoke(query)\n",
    "\n",
    "    return Tool(name=name, description=desc, func=_search)\n",
    "\n",
    "\n",
    "tools = [make_search_tool(retriever, description=\"Searches the configured Nostra corpus.\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03de5b7a",
   "metadata": {},
   "source": [
    "## 3. Build the Agent (Using LangGraph)\n",
    "We will use a pre-built ReAct agent structure from LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "99114074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def build_agent(*, model: str = \"gpt-4o-mini\", temperature: float = 0.0, tools=None):\n",
    "    llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "    return create_agent(llm, tools or [])\n",
    "\n",
    "\n",
    "agent_executor = build_agent(tools=tools)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab8d18b",
   "metadata": {},
   "source": [
    "## 4. Run the Agent\n",
    "Let's ask a question that requires retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d2d3e1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What framework does Nostra use for market resolution?\n",
      "\n",
      "{'model': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 61, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CgSrOeyIh4fwvKfF5Ksn3dyKHbo8K', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--70058f98-b8d6-48d1-b528-28f1ba6ee003-0', tool_calls=[{'name': 'search_docs', 'args': {'__arg1': 'Nostra market resolution framework'}, 'id': 'call_O8XrZs61FOjGRyeSOQV8v6Z1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 61, 'output_tokens': 20, 'total_tokens': 81, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content=\"[Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.'), Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.'), Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.'), Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.')]\", name='search_docs', id='32ca0298-075f-41d5-976c-25a9f7e40fe0', tool_call_id='call_O8XrZs61FOjGRyeSOQV8v6Z1')]}}\n",
      "----\n",
      "{'model': {'messages': [AIMessage(content='The search did not return specific information about the framework Nostra uses for market resolution. However, it indicates that Nostra is a prediction market platform running on Arbitrum. If you need more detailed information about the market resolution framework, I can help you with general concepts or other related topics.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 190, 'total_tokens': 250, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_50906f2aac', 'id': 'chatcmpl-CgSrPB4QgGIv6hihy0XPIAwRUN9Gg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--1116c89f-9643-463a-8bf2-e1b5203a67af-0', usage_metadata={'input_tokens': 190, 'output_tokens': 60, 'total_tokens': 250, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "def run_agent_query(agent, query: str):\n",
    "    print(f\"User: {query}\\n\")\n",
    "    for chunk in agent.stream({\"messages\": [(\"human\", query)]}):\n",
    "        print(chunk)\n",
    "        print(\"----\")\n",
    "\n",
    "\n",
    "run_agent_query(agent_executor, \"What framework does Nostra use for market resolution?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c4f77",
   "metadata": {},
   "source": [
    "## 5. Advanced: Inspecting the Trace\n",
    "The output above shows the agent's reasoning steps:\n",
    "1.  It identifies it needs to search.\n",
    "2.  It calls `search_nostra_docs`.\n",
    "3.  It receives the context.\n",
    "4.  It synthesizes the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fc60b375-a76d-434b-aa74-c87a38cba048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is the purpose of the NST token?\n",
      "\n",
      "{'model': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 60, 'total_tokens': 78, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_50906f2aac', 'id': 'chatcmpl-CgSrRO7okmacuWYkPrkKLbMI7INlv', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--5c205be3-c834-41db-b548-f21199685503-0', tool_calls=[{'name': 'search_docs', 'args': {'__arg1': 'NST token purpose'}, 'id': 'call_XM7XC8eyw6jS8qVu2vEkuYrq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 60, 'output_tokens': 18, 'total_tokens': 78, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content=\"[Document(metadata={'source': 'tokenomics'}, page_content='The native token of Nostra is NST, used for governance and fee rebates.'), Document(metadata={'source': 'tokenomics'}, page_content='The native token of Nostra is NST, used for governance and fee rebates.'), Document(metadata={'source': 'tokenomics'}, page_content='The native token of Nostra is NST, used for governance and fee rebates.'), Document(metadata={'source': 'tokenomics'}, page_content='The native token of Nostra is NST, used for governance and fee rebates.')]\", name='search_docs', id='98b9e7bc-f056-4119-8d6f-c115ae4571de', tool_call_id='call_XM7XC8eyw6jS8qVu2vEkuYrq')]}}\n",
      "----\n",
      "{'model': {'messages': [AIMessage(content='The NST token serves as the native token of Nostra, and its primary purposes are for governance and fee rebates.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 203, 'total_tokens': 227, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CgSrTEk36IATnErz4qMCDDcpRc2rY', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8b0835ca-397b-4fba-adf7-c0b49915f92f-0', usage_metadata={'input_tokens': 203, 'output_tokens': 24, 'total_tokens': 227, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Try another query to demonstrate reuse\n",
    "run_agent_query(agent_executor, \"What is the purpose of the NST token?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911b5793-98f8-4381-a538-f96dfe2432aa",
   "metadata": {},
   "source": [
    "## 6. Bonus Example: Multi-hop question\n",
    "Ask something broader so the agent may retrieve multiple snippets before answering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fc9e6731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Give me a quick overview of Nostra and mention its key features.\n",
      "\n",
      "{'model': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 65, 'total_tokens': 86, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CgSrUG4jbISM7wCWXXSs2xTICoqiP', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--43272bd6-a5bd-4806-be38-0c61c8d44a9f-0', tool_calls=[{'name': 'search_docs', 'args': {'__arg1': 'Nostra overview and key features'}, 'id': 'call_K3wmA2RghAu610vGg2Owq5tt', 'type': 'tool_call'}], usage_metadata={'input_tokens': 65, 'output_tokens': 21, 'total_tokens': 86, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content=\"[Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.'), Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.'), Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.'), Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.')]\", name='search_docs', id='3ce626e3-054e-40b6-8c88-9c66ca731cdc', tool_call_id='call_K3wmA2RghAu610vGg2Owq5tt')]}}\n",
      "----\n",
      "{'model': {'messages': [AIMessage(content='Nostra is a prediction market platform that operates on the Arbitrum blockchain. \\n\\n### Key Features:\\n1. **Prediction Markets**: Users can create and participate in markets that predict the outcome of various events.\\n2. **Decentralization**: Built on a blockchain, ensuring transparency and security.\\n3. **User-Friendly Interface**: Designed to be accessible for both novice and experienced users.\\n4. **Incentives for Participation**: Users can earn rewards for accurate predictions and active participation in the market.\\n\\nIf you need more detailed information or specific aspects of Nostra, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 123, 'prompt_tokens': 195, 'total_tokens': 318, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CgSrVwuiP34c0QicP4Wd4Ld0pfRU7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--512598c5-a4a8-4a7f-80c5-aca9ca66f2ca-0', usage_metadata={'input_tokens': 195, 'output_tokens': 123, 'total_tokens': 318, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Broader query that requires combining multiple documents\n",
    "run_agent_query(agent_executor, \"Give me a quick overview of Nostra and mention its key features.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06327a98",
   "metadata": {},
   "source": [
    "## 7. Reflection + Agentic RAG\n",
    "Use a lightweight reflection pass after the agent responds to catch obvious issues without rerunning retrieval. First the agent executes its tool-augmented RAG plan, then a reviewer pass critiques or amends the answer before you surface it to users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bf7dd1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial answer:\n",
      "Nostra is a prediction market platform that operates on the Arbitrum blockchain. However, there is no specific information available regarding the utility of its token in the provided documents. If you have any other questions or need further details, feel free to ask!\n",
      "\n",
      "Reflection:\n",
      "The answer contains some inaccuracies. Nostra is indeed a prediction market platform, but it operates on the Bitcoin network using the Nostr protocol, not specifically on the Arbitrum blockchain. Additionally, the utility of its token, if applicable, typically includes functions such as governance, staking, or participation in the prediction markets, but specific details about the token's utility were not provided in the answer. For accurate information, it's best to refer to official sources or documentation related to Nostra.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "def collect_agent_answer(agent, query: str) -> str:\n",
    "    final_answer = None\n",
    "    for event in agent.stream({\"messages\": [(\"human\", query)]}):\n",
    "        model_event = event.get(\"model\")\n",
    "        if model_event:\n",
    "            ai_message = model_event[\"messages\"][-1]\n",
    "            final_answer = getattr(ai_message, \"content\", None)\n",
    "    if not final_answer:\n",
    "        raise RuntimeError(\"Agent did not return an answer; check the logs above.\")\n",
    "    return final_answer\n",
    "\n",
    "\n",
    "def run_reflective_agent_query(agent, query: str, *, reviewer_model: str = \"gpt-4o-mini\"):\n",
    "    initial_answer = collect_agent_answer(agent, query)\n",
    "    reviewer = ChatOpenAI(model=reviewer_model, temperature=0.1)\n",
    "    critique = reviewer.invoke([\n",
    "        SystemMessage(content=\"You double-check agent answers for factual accuracy.\"),\n",
    "        HumanMessage(content=f\"Question: {query}\\nAnswer: {initial_answer}\\nProvide a short verification or correction.\"),\n",
    "    ])\n",
    "    print(\"Initial answer:\")\n",
    "    print(initial_answer)\n",
    "    print(\"\\nReflection:\")\n",
    "    print(critique.content)\n",
    "\n",
    "\n",
    "run_reflective_agent_query(agent_executor, \"Summarize Nostra and mention its token utility.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f49b75-4790-4db2-9e50-bab18f89e706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
