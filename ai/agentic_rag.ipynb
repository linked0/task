{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d085a3bc",
   "metadata": {},
   "source": [
    "# Agentic RAG: A Minimal Implementation\n",
    "\n",
    "This notebook demonstrates an **Agentic RAG** system. Unlike traditional RAG (which retrieves -> generates), an Agentic RAG can:\n",
    "1.  **Decide** whether to retrieve information or not.\n",
    "2.  **Refine** its search queries based on initial findings.\n",
    "3.  **Synthesize** information from multiple steps.\n",
    "\n",
    "We will use `LangChain` and `LangGraph` for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ffcd3f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jay/work/task/ai/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "%pip install -q -U langchain langchain-openai langchain-community chromadb langgraph python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d3c094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env if present and expose helper for mandatory keys\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def ensure_env_var(key: str) -> str:\n",
    "    value = os.environ.get(key)\n",
    "    if value:\n",
    "        return value\n",
    "    raise EnvironmentError(f\"Missing required environment variable: {key}\")\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = ensure_env_var(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950a733d",
   "metadata": {},
   "source": [
    "## 1. Setup Vector Store (The \"Knowledge Base\")\n",
    "We'll create a simple in-memory vector store with some dummy data about a fictional company \"Nostra\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "416502be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Iterable, Mapping, Sequence\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CorpusConfig:\n",
    "    collection_name: str = \"nostra_docs\"\n",
    "    default_metadata: Mapping[str, str] = field(default_factory=dict)\n",
    "\n",
    "\n",
    "def _normalize_docs(raw_docs: Iterable[Mapping[str, str]], default_meta: Mapping[str, str]) -> Sequence[Document]:\n",
    "    docs: list[Document] = []\n",
    "    for item in raw_docs:\n",
    "        content = item.get(\"page_content\") or item.get(\"content\")\n",
    "        if not content:\n",
    "            continue\n",
    "        metadata = {**default_meta, **item.get(\"metadata\", {})}\n",
    "        docs.append(Document(page_content=content, metadata=metadata))\n",
    "    if not docs:\n",
    "        raise ValueError(\"At least one document with page_content is required\")\n",
    "    return docs\n",
    "\n",
    "\n",
    "def build_retriever(raw_docs: Iterable[Mapping[str, str]], config: CorpusConfig | None = None):\n",
    "    config = config or CorpusConfig()\n",
    "    docs = _normalize_docs(raw_docs, config.default_metadata)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = Chroma.from_documents(docs, embeddings, collection_name=config.collection_name)\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "DEFAULT_DOCS = [\n",
    "    {\"page_content\": \"Nostra is a prediction market platform running on Arbitrum.\", \"metadata\": {\"source\": \"overview\"}},\n",
    "    {\"page_content\": \"Nostra allows users to trade on future events like Sports and Politics.\", \"metadata\": {\"source\": \"features\"}},\n",
    "    {\"page_content\": \"The native token of Nostra is NST, used for governance and fee rebates.\", \"metadata\": {\"source\": \"tokenomics\"}},\n",
    "    {\"page_content\": \"Nostra uses a CTF (Conditional Token Framework) for its market resolution.\", \"metadata\": {\"source\": \"tech\"}},\n",
    "]\n",
    "\n",
    "retriever = build_retriever(DEFAULT_DOCS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d13540",
   "metadata": {},
   "source": [
    "## 2. Define Tools\n",
    "The agent needs a tool to access the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "631272d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "\n",
    "def make_search_tool(retriever, *, name: str = \"search_docs\", description: str | None = None):\n",
    "    desc = description or \"Retrieves grounded knowledge snippets for the agent.\"\n",
    "\n",
    "    def _search(query: str):\n",
    "        return retriever.invoke(query)\n",
    "\n",
    "    return Tool(name=name, description=desc, func=_search)\n",
    "\n",
    "\n",
    "tools = [make_search_tool(retriever, description=\"Searches the configured Nostra corpus.\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03de5b7a",
   "metadata": {},
   "source": [
    "## 3. Build the Agent (Using LangGraph)\n",
    "We will use a pre-built ReAct agent structure from LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "99114074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def build_agent(*, model: str = \"gpt-4o-mini\", temperature: float = 0.0, tools=None):\n",
    "    llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "    return create_agent(llm, tools or [])\n",
    "\n",
    "\n",
    "agent_executor = build_agent(tools=tools)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab8d18b",
   "metadata": {},
   "source": [
    "## 4. Run the Agent\n",
    "Let's ask a question that requires retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d2d3e1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What framework does Nostra use for market resolution?\n",
      "\n",
      "{'model': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 61, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_50906f2aac', 'id': 'chatcmpl-CgSdsatyGeS5QMTb2jxp0Ai6bJXpm', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--d3e3e08a-c223-4365-97cb-d09602a48f1d-0', tool_calls=[{'name': 'search_docs', 'args': {'__arg1': 'Nostra market resolution framework'}, 'id': 'call_25XwcTsiVr3M8UkRa77ySoyk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 61, 'output_tokens': 20, 'total_tokens': 81, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content=\"[Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.'), Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.'), Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.'), Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.')]\", name='search_docs', id='ad100637-8280-47f5-825c-af63a8e0a44c', tool_call_id='call_25XwcTsiVr3M8UkRa77ySoyk')]}}\n",
      "----\n",
      "{'model': {'messages': [AIMessage(content='The search did not return specific information about the framework Nostra uses for market resolution. However, it indicates that Nostra is a prediction market platform running on Arbitrum. If you need more detailed information about the market resolution framework, I can help you with general concepts or other related topics.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 190, 'total_tokens': 250, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_50906f2aac', 'id': 'chatcmpl-CgSdvpShrYhL3Id0Cr5bPkwIp4FF3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--2ea072b9-d445-40d1-a403-21b54807ead9-0', usage_metadata={'input_tokens': 190, 'output_tokens': 60, 'total_tokens': 250, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "def run_agent_query(agent, query: str):\n",
    "    print(f\"User: {query}\\n\")\n",
    "    for chunk in agent.stream({\"messages\": [(\"human\", query)]}):\n",
    "        print(chunk)\n",
    "        print(\"----\")\n",
    "\n",
    "\n",
    "run_agent_query(agent_executor, \"What framework does Nostra use for market resolution?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c4f77",
   "metadata": {},
   "source": [
    "## 5. Advanced: Inspecting the Trace\n",
    "The output above shows the agent's reasoning steps:\n",
    "1.  It identifies it needs to search.\n",
    "2.  It calls `search_nostra_docs`.\n",
    "3.  It receives the context.\n",
    "4.  It synthesizes the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fc60b375-a76d-434b-aa74-c87a38cba048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is the purpose of the NST token?\n",
      "\n",
      "{'model': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 60, 'total_tokens': 78, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CgSdxBogSdl0vWB9x5JLkMELiAZ46', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--071eb433-8eb7-4921-84d5-2d2281ef38fa-0', tool_calls=[{'name': 'search_docs', 'args': {'__arg1': 'NST token purpose'}, 'id': 'call_p1IIzMA4HqZ0OETmFtM6rF3z', 'type': 'tool_call'}], usage_metadata={'input_tokens': 60, 'output_tokens': 18, 'total_tokens': 78, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content=\"[Document(metadata={'source': 'tokenomics'}, page_content='The native token of Nostra is NST, used for governance and fee rebates.'), Document(metadata={'source': 'tokenomics'}, page_content='The native token of Nostra is NST, used for governance and fee rebates.'), Document(metadata={'source': 'tokenomics'}, page_content='The native token of Nostra is NST, used for governance and fee rebates.'), Document(metadata={'source': 'tokenomics'}, page_content='The native token of Nostra is NST, used for governance and fee rebates.')]\", name='search_docs', id='aa393ba2-4c88-4eb9-8949-7f9c4a7a0244', tool_call_id='call_p1IIzMA4HqZ0OETmFtM6rF3z')]}}\n",
      "----\n",
      "{'model': {'messages': [AIMessage(content='The NST token serves as the native token of Nostra, and its primary purposes are for governance and fee rebates.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 203, 'total_tokens': 227, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CgSdy2c4o8PpaybgL94GSeVHEn2YK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--9b9b5f7c-b115-47f6-8df2-0eba128fcbcd-0', usage_metadata={'input_tokens': 203, 'output_tokens': 24, 'total_tokens': 227, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Try another query to demonstrate reuse\n",
    "run_agent_query(agent_executor, \"What is the purpose of the NST token?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911b5793-98f8-4381-a538-f96dfe2432aa",
   "metadata": {},
   "source": [
    "## 6. Bonus Example: Multi-hop question\n",
    "Ask something broader so the agent may retrieve multiple snippets before answering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fc9e6731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Give me a quick overview of Nostra and mention its key features.\n",
      "\n",
      "{'model': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 65, 'total_tokens': 86, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_50906f2aac', 'id': 'chatcmpl-CgSe8ruvKx1F3ajVOt4zhqrPdsimf', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--2852a8db-1aec-49d0-807b-7275bf925f21-0', tool_calls=[{'name': 'search_docs', 'args': {'__arg1': 'Nostra overview and key features'}, 'id': 'call_WFx69fvMBK0V9FewzhMe8NOO', 'type': 'tool_call'}], usage_metadata={'input_tokens': 65, 'output_tokens': 21, 'total_tokens': 86, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content=\"[Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.'), Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.'), Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.'), Document(metadata={'source': 'overview'}, page_content='Nostra is a prediction market platform running on Arbitrum.')]\", name='search_docs', id='6ac4ae96-050a-4019-ae40-f6a85a154bdb', tool_call_id='call_WFx69fvMBK0V9FewzhMe8NOO')]}}\n",
      "----\n",
      "{'model': {'messages': [AIMessage(content='Nostra is a prediction market platform that operates on the Arbitrum blockchain. \\n\\n### Key Features:\\n1. **Prediction Markets**: Users can create and participate in markets that predict the outcome of future events.\\n2. **Decentralization**: Built on a blockchain, ensuring transparency and security.\\n3. **User-Friendly Interface**: Designed to be accessible for both novice and experienced users.\\n4. **Incentives for Participation**: Users can earn rewards for accurate predictions and active participation in the market.\\n\\nIf you need more specific details or additional features, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 120, 'prompt_tokens': 195, 'total_tokens': 315, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_50906f2aac', 'id': 'chatcmpl-CgSeCfHjiTTqxFDuiwHHdfjPquxT4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--334edc9a-a82e-4ad5-9a7e-d37526bf6bba-0', usage_metadata={'input_tokens': 195, 'output_tokens': 120, 'total_tokens': 315, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Broader query that requires combining multiple documents\n",
    "run_agent_query(agent_executor, \"Give me a quick overview of Nostra and mention its key features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c771634-5407-416b-894e-96f9d4a99713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
